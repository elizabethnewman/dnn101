{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "AZR4EZ30NQxv",
    "4QKhWYC-xwMt"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard",
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Neural Networks (CNNs)\n",
    "\n",
    "CNNs are **the** tool for imaging tasks.  Convolutions can capture desirable properties of images, such as translation invariance, and are computed efficiently on GPUs.  The number of weights needed for each convolution is independent of the number of layer features, hence CNNs can tackle problems very high dimensional data as well.\n",
    "\n",
    "### Outcomes \n",
    "In this tutorial, you will\n",
    "\n",
    "*   load the MNIST dataset from torchvision\n",
    "*   learn how to construct a convolutional neural network\n",
    "*   learn how to use a GPU for training\n",
    "\n",
    "### Suggested Activities\n",
    "\n",
    "\n",
    "*  How does the network architecture affect the performance?  Play with the different parameters in convolutional layers.\n",
    "*  The MNIST dataset is notoriously easy to classify.  Explore other datasets in PyTorch and see how you can \n",
    "\n",
    "Check out the [PyTorch Documentation](https://pytorch.org/docs/stable/index.html) as you explore!\n",
    "\n",
    "The network used for this notebook follows the example in  https://github.com/pytorch/examples/tree/main/mnist.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "fR4M5Pn3NXzh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Import Packages\n",
    "\n",
    "We start by importing the necessary packages to run our code.  We are installing the following packages:\n",
    "\n",
    "   * deep learning toolbox [Pytorch](https://pytorch.org/)\n",
    "   * vision toolbox [torchvision](https://pytorch.org/vision/stable/index.html)\n",
    "   * visualization toolbox [Matplotlib](https://matplotlib.org/)\n",
    "   * DNN101 repository [https://github.com/elizabethnewman/dnn101](https://github.com/elizabethnewman/dnn101)."
   ],
   "metadata": {
    "id": "AZR4EZ30NQxv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python -m pip install git+https://github.com/elizabethnewman/dnn101.git\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de4ULou5Ghie",
    "outputId": "9183e0fc-e736-4f2c-f0c1-a6c225e7015c",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHPt_1WLGX5X"
   },
   "outputs": [],
   "source": [
    "import dnn101\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Setup Device\n",
    "\n",
    "We will check and use the GPU if available. \n",
    "\n",
    "You can use a GPU on Google Colab by following these instructions: \n",
    "\n",
    "*   Locate the Runtime menu (top left of your screen)\n",
    "*   Select Runtime -> Change runtime type. A dialogue box will open.  \n",
    "*   Coose GPU under the Hardware accelarator dropdown list.  \n",
    "*   Click save and you're on a GPU!"
   ],
   "metadata": {
    "id": "3GDJr-CXS2M0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# create data\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\")\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "train_kwargs = {'batch_size': 32}\n",
    "test_kwargs = {'batch_size': 32}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1, 'pin_memory': True, 'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)"
   ],
   "metadata": {
    "id": "whl_fhE8S4dA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Load the Data\n",
    "\n"
   ],
   "metadata": {
    "id": "FT70M5MTNfOI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# data parameters\n",
    "n_train = 1000\n",
    "n_val = 100\n",
    "n_test = 100\n",
    "seed = 123       # seed for reproducibility\n",
    "\n",
    "# set seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "# load data with transforms to normalize the images\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "dataset1 = datasets.MNIST('../raw_data', train=True, download=True, transform=transform)\n",
    "dataset2 = datasets.MNIST('../raw_data', train=False, transform=transform)\n",
    "\n",
    "# create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "val_loader = deepcopy(train_loader)\n",
    "val_loader.train = False\n",
    "val_loader.shuffle = False\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "# create smaller datasets for faster experimentation if preferred\n",
    "if n_train is not None:\n",
    "    train_idx = torch.randperm(train_loader.dataset.data.shape[0])\n",
    "    train_loader.dataset.data = train_loader.dataset.data[train_idx[:n_train]]\n",
    "    train_loader.dataset.targets = train_loader.dataset.targets[train_idx[:n_train]]\n",
    "\n",
    "if n_val is not None:\n",
    "    val_loader.dataset.data = val_loader.dataset.data[train_idx[n_train:n_train + n_val]]\n",
    "    val_loader.dataset.targets = val_loader.dataset.targets[train_idx[n_train:n_train + n_val]]\n",
    "\n",
    "if n_test is not None:\n",
    "    # test\n",
    "    test_idx = torch.randperm(test_loader.dataset.data.shape[0])\n",
    "    test_loader.dataset.data = test_loader.dataset.data[test_idx[:n_test]]\n",
    "    test_loader.dataset.targets = test_loader.dataset.targets[test_idx[:n_test]]\n"
   ],
   "metadata": {
    "id": "_RxOR5E_HOxe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Train!\n",
    "\n",
    "This block is the heart of DNN training and consists of four main steps\n",
    "1. Define the architecture of the DNN (for this notebook, we choose [Linear Layers](https://pytorch.org/docs/stable/nn.html#linear-layers) and [Activation Functions](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity))\n",
    "2. Choose a loss function ([PyTorch Loss Functions](https://pytorch.org/docs/stable/nn.html#loss-functions)).  For regression, we use the [Mean Squared Error Loss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss). \n",
    "3. Choose an optimizer ([PyTorch Optimizers](https://pytorch.org/docs/stable/optim.html?highlight=optim#torch.optim.Optimizer))\n",
    "4. Train with stochastic optimization.  \n",
    "\n",
    "If you change parameters, be sure to run all blocks in this section to make sure everything is connected properly."
   ],
   "metadata": {
    "id": "2OJhxaR9vh7O"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Architecture\n",
    "\n",
    "Take a look at the documentation for the new layers!\n",
    "\n",
    "\n",
    "*   [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html): apply a translation-invariant operator with a small number of weights efficiently on a GPU\n",
    "*   [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html): effectively a coarsening of the image pixels\n",
    "*   [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html): effectively a way to avoid overfitting\n",
    "\n",
    "\n",
    "\n",
    "Note that the MNIST images are stored as $(N, 1, 28, 28)$, meaning we have $N$ images of size $28 \\times 28$ with $1$ channel each (i.e., the images are grayscale)."
   ],
   "metadata": {
    "id": "xTWZ8_S1xsOy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# a reshaping layer for convenience\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "\n",
    "# create architecture\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 3, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, 3, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Dropout(0.25),\n",
    "    View((-1, 12 * 12 * 64)),\n",
    "    nn.Linear(12 * 12 * 64, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)"
   ],
   "metadata": {
    "id": "ipXB5NITxrmR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from dnn101.cnn.plotting import plot_Conv2d_filters, plot_CNN_features\n",
    "\n",
    "print(net)\n",
    "plot_Conv2d_filters(net, 16)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "x, _ = next(iter(train_loader))\n",
    "plot_CNN_features(net, x[0:1].to(device))\n",
    "plt.show()\n",
    "\n",
    "plot_CNN_features(net, x[3:4].to(device), n_features=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "khqO-s0RcVey"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Loss Function\n",
    "\n",
    "In PyTorch, the default [cross entropy loss function](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)  given by\n",
    "\\begin{align*}\n",
    "L(f(\\mathbf{y},\\mathbf{\\theta}), c) = -\\mathbf{e}_c^\\top \\log\\sigma(f(\\mathbf{y},\\mathbf{\\theta}))]\n",
    "\\end{align*}\n",
    "where $c$ is the class to which $\\mathbf{y}$ belongs, $\\mathbf{e}_c$ is the standard basis vector with a $1$ in the $c$-th component.  The softmax function $\\sigma$ is given by \n",
    "  \\begin{align*}\n",
    "  \\sigma(\\mathbf{z}) = \\frac{\\exp(\\mathbf{z})}{\\mathbf{e}^\\top \\exp(\\mathbf{z})}\n",
    "  \\end{align*}\n",
    "where $\\mathbf{e}$ is the constant vector of all ones. "
   ],
   "metadata": {
    "id": "4QKhWYC-xwMt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loss = torch.nn.CrossEntropyLoss() "
   ],
   "metadata": {
    "id": "ub4fYRsNxyjd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Optimizer and Scheduler"
   ],
   "metadata": {
    "id": "7LBjcyvxy8pZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, 0.9)"
   ],
   "metadata": {
    "id": "zi-viz3Ny_w0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Train!"
   ],
   "metadata": {
    "id": "XTdL_meRzAHH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython import display\n",
    "mpl.rcParams['figure.figsize'] = (16, 6)\n",
    "mpl.rcParams['lines.linewidth'] = 8\n",
    "mpl.rcParams['font.size'] = 10\n",
    "\n",
    "# import training\n",
    "from dnn101.utils import evaluate, train\n",
    "\n",
    "# printing and plotting options (only one can be True)\n",
    "verbose = False             # printouts\n",
    "show_plot = not verbose     # plot to show training\n",
    "\n",
    "# set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# store and print results\n",
    "info = {\n",
    "    'headers': ('epoch', 'lr', 'run_loss', 'run_acc', 'train_loss', 'train_acc', 'valid_loss', 'valid_acc'),\n",
    "    'formats': '{:<15d}{:<15.4e}{:<15.4e}{:<15.4f}{:<15.4e}{:<15.4f}{:<15.4e}{:<15.4f}',\n",
    "    'values': []\n",
    "    }\n",
    "\n",
    "loss_train, acc_train = evaluate(net, loss, train_loader, device=device)\n",
    "loss_val, acc_val = evaluate(net, loss, val_loader, device=device)\n",
    "info['values'].append([-1, optimizer.param_groups[0]['lr'], 0.0, 0.0, loss_train, acc_train, loss_val, acc_val])\n",
    "\n",
    "if verbose:\n",
    "    print(('{:<15s}' * len(info['headers'])).format(*info['headers']))\n",
    "    print(info['formats'].format(*info['values'][-1]))\n",
    "\n",
    "max_epochs = 10\n",
    "for epoch in range(max_epochs):\n",
    "    # learn\n",
    "    loss_running, acc_running = train(net, loss, train_loader, optimizer, device=device)\n",
    "\n",
    "    # evaluate\n",
    "    loss_train, acc_train = evaluate(net, loss, train_loader, device=device)\n",
    "    loss_val, acc_val = evaluate(net, loss, val_loader, device=device)\n",
    "\n",
    "    # store and print or plot results\n",
    "    info['values'].append([epoch, optimizer.param_groups[0]['lr'], loss_running, acc_running, loss_train, acc_train, loss_val, acc_val])\n",
    "    if verbose:\n",
    "        print(info['formats'].format(*info['values'][-1]))\n",
    "\n",
    "    if show_plot:\n",
    "      # show same sample\n",
    "      next(x for i, (x, _) in enumerate(val_loader) if i <= 0)\n",
    "      plot_CNN_features(net, x[5:6].to(device),  16)\n",
    "      plt.title('epoch = %d' % epoch)\n",
    "\n",
    "      display.display(plt.gcf())\n",
    "      display.clear_output(wait=True)\n",
    "      plt.clf()\n",
    "\n",
    "      \n",
    "mpl.rcParams.update(mpl.rcParamsDefault)"
   ],
   "metadata": {
    "id": "jS6h2MvbJBEf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "outputId": "9de5b4e6-fb3a-46ff-ca4a-39046fe159a9",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Inference\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# final losses and accuracies\n",
    "loss_train, acc_train = evaluate(net, loss, train_loader, device=device)\n",
    "loss_val, acc_val = evaluate(net, loss, val_loader, device=device)\n",
    "loss_test, acc_test = evaluate(net, loss, test_loader, device=device)\n",
    "\n",
    "print('Train: Loss = %0.4e, Acc = %0.2f' % (loss_train, acc_train))\n",
    "print('Valid: Loss = %0.4e, Acc = %0.2f' % (loss_val, acc_val))\n",
    "print('Test: Loss = %0.4e, Acc = %0.2f' % (loss_test, acc_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting the features of some samples\n",
    "next(x for i, (x, _) in enumerate(val_loader) if i <= 0)\n",
    "plot_CNN_features(net, x[5:6].to(device),  16)\n",
    "plt.title('sample 1')\n",
    "plt.show()\n",
    "\n",
    "plot_CNN_features(net, x[10:11].to(device),  16)\n",
    "plt.title('sample 2')\n",
    "plt.show()\n",
    "\n",
    "plot_CNN_features(net, x[30:31].to(device),  16)\n",
    "plt.title('sample 3')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting some convolutional filters\n",
    "plot_Conv2d_filters(net, 16)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
